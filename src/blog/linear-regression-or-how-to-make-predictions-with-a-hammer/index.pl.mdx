---
title: Regresja liniowa, czyli jak wrÃ³Å¼yÄ‡ za pomocÄ… mÅ‚otka?
sub_title: To jest prawdopodobnie, najbardziej podstawowa metoda wykorzystywana w uczeniu maszynowym. Nie moÅ¼esz jej nie znaÄ‡! 
date: 2021-04-17T19:15:02.321Z
hero_image: ./linear-regression-hero.jpg
hero_image_alt: Wyrenderowany w 3D obraz przedstawiajÄ…cy rÃ³Å¼owe pÅ‚aszczyzny lub Å›ciany
hero_image_credit_text: Photo by  Ivan Liu Hu  on Unsplash
hero_image_author: Ivan Liu Hu
hero_image_author_link: https://unsplash.com/@ivanliuhu?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText
hero_image_source: Unsplash
hero_image_credit_link: https://unsplash.com/photos/pgSG9d2iNFc?utm_source=unsplash&utm_medium=referral&utm_content=creditShareLink
reading_time: 7min
tags:
  - Uczenie maszynowe
  - Statystyka
author: Krzysztof Skwarski
---

###### KaÅ¼dy wspÃ³Å‚czesny, Å¼ywy organizm - czÄ™sto nieÅ›wiadomy tego faktu - funkcjonuje balansujÄ…c na ostrej krawÄ™dzi rozdzielajÄ…cej Å›wiat jaki doskonale znamy od tego, ktÃ³rego napewno nie chcemy. DziaÅ‚alnoÅ›Ä‡ czÅ‚owieka, czyli powiedzmy wprost - kaÅ¼dego z nas - przybliÅ¼yÅ‚a granicÄ™, ktÃ³rej przekroczenie oznacza bezpowrotnÄ… utratÄ™ naszego Å¼yciodajnego Å›rodowiska. Szkodliwa emisja tzw. gazÃ³w cieplarnianych, to tylko jeden z wielu przykÅ‚adÃ³w tej bezlitosnej dewastacji. Niestety w tym poÅ›cie nie rozwiÄ…Å¼emy palÄ…cych problemÃ³w, ale posÅ‚uÅ¼Ä… one jako Å›rodek do zapoznania siÄ™ z jednÄ… z metod uÅ¼ywanych w uczeniu maszynowym - regresji liniowej.

### Statystyka na pomoc

Statystyka stara siÄ™ znaleÅºÄ‡ odpowiedÅº na wiele trudnych pytaÅ„, wykorzystujÄ…c do tego celu dane. Do takich zagadnieÅ„ moÅ¼emy zaliczyÄ‡ prÃ³bÄ™ znalezienia i opisania zaleÅ¼noÅ›ci pomiÄ™dzy cechami, czyli inaczej mÃ³wiÄ…c odpowiedzi na pytanie: *jak zmiana wartoÅ›ci jednej cechy wpÅ‚ynie na wartoÅ›Ä‡ innej cechy?*.  

JednÄ… z najprostszych i najbardziej podstawowych metod badania zaleÅ¼noÅ›ci pomiÄ™dzy cechÄ… (*zmiennÄ… niezaleÅ¼nÄ…*) a odpowiedziÄ… (inaczej mÃ³wiÄ…c *zmiennÄ… zaleÅ¼nÄ…* lub *targetem*) jest metoda **regresji liniowej**. Poznanie stojÄ…cej za niÄ… koncepcji, moÅ¼e okazaÄ‡ siÄ™ kluczowe do zrozumienia dziaÅ‚ania innych modeli. Dotyczy to zarÃ³wno obszaru uczenia maszynowego jak i sieci neuronowych.  

#### O budowie mÅ‚otka sÅ‚Ã³w kilka  
Metoda regresji liniowej zakÅ‚ada, Å¼e pomiÄ™dzy wyÅ¼ej wspomnianymi zmiennymi a wiÄ™c cechÄ… i targetem wystÄ™puje *liniowa zaleÅ¼noÅ›Ä‡*. W swojej najprostszej odsÅ‚onie, pozwala ona na predykcjÄ™ iloÅ›ciowej odpowiedzi (oznaczmy jÄ… jako Y) na podstawie zmian wartoÅ›ci jakiejÅ› cechy (oznaczmy jÄ… jako X):  
$$
Y\approx \beta_{0} + \beta_{1}X \tag{1}
$$

Rzut okiem na trzy kluczowe aspekty modelu, pozwolÄ… nam go lepiej zrozumieÄ‡:  

![Wykres ilustrujÄ…cy zasadÄ™ znaczenie wspÃ³Å‚czynnikÃ³w regresji B0 i B1](./regression_coefficients.jpg)  

**Aspekt 1: wspÃ³Å‚czynniki regresji**  
IstotÄ… dziaÅ‚ania metody jest trenowanie modelu na tzw. zbiorze treningowym, ktÃ³re umoÅ¼liwia obliczenie wartoÅ›ci wspÃ³Å‚czynnikÃ³w regresji $\beta_{0}$ i $\beta_{1}$.  
WspÃ³Å‚czynniki regresji liniowej $\beta_{0}$, $\beta_{1}$ odpowiadajÄ… za przebieg prostej okreÅ›lonej wzorem (1), a konkretnie za jej nachylenie wzglÄ™dem osi oX ($\beta_{1}$) oraz miejsce przeciÄ™cia prostej z osiÄ… oY ($\beta_{0}$). Warto zauwaÅ¼yÄ‡, Å¼e z definicji wspÃ³Å‚czynnika $\beta_{1} = \frac{\Delta y_{i}}{\Delta x_{i}}$ wynika, Å¼e jest to tangens kÄ…ta jaki tworzy prosta z osiÄ… oX.

![Wykres model regresji liniowej](./regression_model.jpg) 

**Aspekt 2: przebieg krzywej regresji**  
ZaleÅ¼y nam na tym, aby znaleÅºÄ‡ takie wartoÅ›ci wspÃ³Å‚czynnikÃ³w $\beta_{0}$ i $\beta_{1}$, dla ktÃ³rych linia prosta, okreÅ›lona przez wzÃ³r (1) przebiega w jak najmniejszej odlegÅ‚oÅ›ci od punktÃ³w reprezentujÄ…cych rzeczywiste obserwacje. Wyznaczona linia prosta stanowi zbiÃ³r punktÃ³w, bÄ™dÄ…cych predykcjami naszego modelu.  

![Wykres ilustrujÄ…cy bÅ‚Ä…d predykcji](./regression_error.jpg)

**Aspekt 3: bÅ‚Ä…d predykcji**  
OdlegÅ‚oÅ›Ä‡ miÄ™dzy wartoÅ›ciÄ… przewidzianÄ… przez model ($\hat{y}_{i}$) a rzeczywistÄ… obserwacjÄ… ($y_{i}$) to nic innego jak bÅ‚Ä…d predykcji ($e_{i}$):<br class='before-equation'/>
$e_{i} = y_{i} - \hat{y}_{i}$  

Optymalnym rozwiÄ…zaniem dla modelu jest zminimalizowanie ogÃ³lnego bÅ‚Ä™du predykcji dla wszystkich obserwacji. Wykorzystujemy do tego **metodÄ™ najmniejszych kwadratÃ³w** (*residual sum of squares*):  
$$
RSS = e_{1}^2 + e_{2}^2 + e_{3}^2 + \dotsb + e_{i}^2 = \sum_{i=1}^n (y_{i} - \hat{y}_{i})^2
$$  

Podniesienie kaÅ¼dego bÅ‚Ä™du do kwadratu ma na celu unikniÄ™cie sytuacji wzajemnego "znoszenia siÄ™" bÅ‚Ä™dÃ³w niedoszacowania i przeszacowania predykcji. ZaÅ‚Ã³Å¼my, Å¼e w zbiorze rzeczywistych obserwacji mamy punkty o wartoÅ›ciach 5, 8, 7, 10. Nasz model zwrÃ³ciÅ‚ predykcje dla tych punktÃ³w o wartoÅ›ciach odpowiednio 6, 7, 8, 9. GdybyÅ›my teraz sprÃ³bowali zsumowaÄ‡ bÅ‚Ä™dy predykcji $e_{i}$ dla tych obserwacji otrzymalibyÅ›my:

$$
e_{1}+e_{2}+e_{3}+e_{4} = (5-6)+(8-7)+(7-8)+(10-9) = -1+1-1+1 = 0
$$

PowinniÅ›my wysnuÄ‡ wniosek, Å¼e model dziaÅ‚a idealnie, gdyÅ¼ nie popeÅ‚nia bÅ‚Ä™du (bÅ‚Ä…d wynosi 0). Przeczy to w zupeÅ‚noÅ›ci rzeczywistej sytuacji. UÅ¼ycie RSS, uwalnia nas od tego problemu:

$$
e_{1}^2+e_{2}^2+e_{3}^2+e_{4}^2 = (5-6)^2+(8-7)^2+(7-8)^2+(10-9)^2 = 1+1+1+1 = 4
$$

#### Jak to policzyÄ‡?
WspomniaÅ‚em wczeÅ›niej, Å¼e model regresji liniowej wykorzystuje dane treningowe do kalkulacji wspÃ³Å‚czynnikÃ³w $\beta_{0}$, $\beta_{1}$ za pomocÄ… metody najmniejszych kwadratÃ³w. W uproszczeniu istota tej metody sprowadza siÄ™ do kalkulacji wspÃ³Å‚czynnikÃ³w za pomocÄ… wzorÃ³w:

$$
\beta_{1} = \frac{\sum_{i=1}^{n}(x_{i} - \bar{x})(y_{i} - \bar{y})}{\sum_{i=1}^{n}(x_{i} - \bar{x})^2}\tag{2}
$$

$$
\beta_{0} = \bar{y} - \beta_{1}\bar{x}\tag{3}
$$

W powyÅ¼szych wzorach $\bar{x}$ oraz $\bar{y}$ oznaczajÄ… odpowiednio wartoÅ›Ä‡ Å›redniÄ… dla cechy oraz wartoÅ›Ä‡ Å›redniÄ… dla targetu. Fajnie, tylko... o co w tym chodzi? O ile bardzo Å‚atwo jest sobie wytÅ‚umaczyÄ‡ rÃ³wnanie (3), gdyÅ¼ na pierwszy rzut oka widaÄ‡, Å¼e jest to matematyczna "konsekwencja" wynikajÄ…ca z samego rÃ³wnania regresji (1) (wystarczy je po prostu przeksztaÅ‚ciÄ‡), o tyle rÃ³wnanie na $\beta_{1}$ (2) nie jest tak oczywiste na poziomie intuicyjnego zrozumienia. SprÃ³bujmy siÄ™ jednak nad tym chwilkÄ™ zastanowiÄ‡.  



![Wykres zaleÅ¼noÅ›ci nachylenia krzywej regresji w zaleÅ¼noÅ›ci od B1 (B1 =1)](./coefficient_b1_1.jpg)  

Wiemy, Å¼e $\beta_{1}$ odpowiada za nachylenie prostej regresji wzglÄ™dem osi oX. ZaÅ‚Ã³Å¼my najpierw, Å¼e $x_{i} =y_{i}$. Wtedy: <br class='before-equation' />
$\beta_{1} = \frac{\sum_{i=1}^{n}(x_{i} - \bar{x})(x_{i} - \bar{x})}{\sum_{i=1}^{n}(x_{i} - \bar{x})^2} = \frac{\sum_{i=1}^{n}(x_{i} - \bar{x})^2}{\sum_{i=1}^{n}(x_{i} - \bar{x})^2} = 1$
Oznacza to, Å¼e kaÅ¼dej zmianie wartoÅ›ci cechy (X) oznacza dokÅ‚adnie taka sama co do wartoÅ›ci zmiana targetu (Y). Na wykresie, bÄ™dzie siÄ™ to manifestowaÅ‚o prostÄ… nachylonÄ… o 45 stopni do osi oX ($tg45^\circ =1$).  

![Wykres zaleÅ¼noÅ›ci nachylenia krzywej regresji w zaleÅ¼noÅ›ci od B1 (B1<1)](./coefficient_b1_less.jpg)

Teraz popatrz na inny przypadek. Zmiana wartoÅ›ci cechy powoduje znacznie mniejszÄ… reakcjÄ™ targetu, czyli $\Delta x > \Delta y$. Wtedy dla kaÅ¼dej pary $x_{i}, y_{i}$ prawdziwa bÄ™dzie nierÃ³wnoÅ›Ä‡:<br class='before-equation' /> $(x_{i} - \bar{x})(y_{i} - \bar{y}) <(x_{i} - \bar{x})^2$ (kwadrat dowolnej liczby bÄ™dzie zawsze wiÄ™kszy od iloczynu tej liczby i liczby od dniej mniejszej).  
Co to oznacza dla wspÃ³Å‚czynnika $\beta_{1}$ ? JeÅ¼eli bÄ™dziemy dzieliÄ‡ liczbÄ™ mniejszÄ… przez wiÄ™kszÄ…, to zawsze otrzymamy wynik mniejszy niÅ¼ 1: <br class='before-equation' />$\beta_{1} = \frac{\sum_{i=1}^{n}(x_{i} - \bar{x})(y_{i} - \bar{y})}{\sum_{i=1}^{n}(x_{i} - \bar{x})^2} < 1$  
Linia prosta utworzona przez rÃ³wnanie regresji oparte na na takim wspÃ³Å‚czynniku $\beta_{1}$ bÄ™dzie nachylona wzglÄ™dem osi oX pod kÄ…tem mniejszym niÅ¼ 45 stopni. Jest to zgodne z naszÄ… intuicjÄ…, gdyÅ¼ wiemy, Å¼e tangens kÄ…ta w przedziale od $0^\circ$ do $45^\circ$ przyjmuje wartoÅ›ci mniejsze od 1.  

Mam nadziejÄ™, Å¼e ma to teraz dla Ciebie wiÄ™kszy sens.

#### Bierzemy mÅ‚otek do rÄ™ki czyli, jak to dziaÅ‚a w praktyce?
Na szczÄ™Å›cie nie musisz wykonywaÄ‡ powyÅ¼szych obliczeÅ„ samodzielnie (o ile nie naleÅ¼ysz do osÃ³b, ktÃ³re to bardzo lubiÄ…). Biblioteka scikit-learn dostarcza Ci niezbÄ™dnego zestawu narzÄ™dzi, ktÃ³ry w bardzo Å‚atwy sposÃ³b pozwala zbudowaÄ‡ model regresji liniowej dla Twoich danych.  

Postaramy siÄ™ zbadaÄ‡, jaki wpÅ‚yw na efekt globalnego ocieplania ma emisja dwutlenku wÄ™gla oraz przewidzieÄ‡, jaka bÄ™dzie skala tego zjawiska w niedalekiej przyszÅ‚oÅ›ci. Do wytrenowania modelu uÅ¼yjemy danych opublikowanych w bazie EDGAR (Emissions Database for Global Atmospheric Research), przygotowywanych przez KomisjÄ™ EuropejskÄ…. Raport zawiera m.in. estymacje emisji gazÃ³w cieplarnianych, opracowanych dla kaÅ¼dego kraju (w skali Å›wiatowej), siÄ™gajÄ…ce swojÄ… historiÄ… aÅ¼ do roku 1970 i jest co roku aktualizowany. Gotowy plik w formacie MS Excel moÅ¼na pobraÄ‡ ze oficjalnej strony Komisji Europejskiej <a href='https://edgar.jrc.ec.europa.eu/report_2021#data_download' class='visible' target='_blank' rel='noreferer'>EDGAR</a>  

```python lineNumbers
import pandas as pd
import numpy as np

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

import matplotlib.pyplot as plt
%matplotlib inline
```  
Tradycyjnie rozpoczynamy od importu niezbÄ™dnych bibliotek. Potrzebne nam bÄ™dÄ… biblioteki Pandas oraz Numpy do wykonania przeksztaÅ‚ceÅ„ danych. Dodatkowo zaangaÅ¼ujemy bibliotekÄ™ matplotlib do przygotowania wizualizacji. Zbudowanie modelu i predykcjÄ™ poszukiwanych przez nas wartoÅ›ci umoÅ¼liwi wspominana wczeÅ›niej biblioteka scikit-learn, z ktÃ³rej zaimportujemy model regresji liniowej **LinearRegression**, metrykÄ™ **mean_squared_error** do oceny skutecznoÅ›ci modelu oraz funkcjÄ™: **train_test_split**, jako wsparcie w procesie trenowania.  

Teraz wczytamy dane z pobranego pliku programu Excel. Chcemy w naszej analizie skupiÄ‡ siÄ™ na okreÅ›leniu globalnego stopnia emisji CO<sub>2</sub>, wobec czego skorzystany z informacji zawartych w arkuszu *"fossil_CO2_totals_by_country"*. Zawiera on dane, ukazujÄ…ce poziom emisji CO<sub>2</sub>, wyraÅ¼one w megatonach (Mt) w ciÄ…gu jednego roku. KaÅ¼da z kolumn zawiera wartoÅ›ci dla jednego roku, w poszczegÃ³lnych krajach. W konsekwencji kaÅ¼dy wiersz zawiera szereg czasowy dla jednego kraju (nie liczÄ…c pozycji dotyczÄ…cych transportu lotniczego oraz morskiego). Najistotniejszy dla nas jest zapis w ostatnim wierszu *"GLOBAL TOTAL"*, podsumowujÄ…cy wartoÅ›ci dla caÅ‚ego Å›wiata:  

|country_name	|1970	    |1971	    |1972	    |1973	    |â€¦    |2019    |
|:---         |:---:    |:---:    |:---:    |:---:    |:---:|--- :   |
|Afghanistan	|1,48	    |1,48	    |1,53	    |1,49   	|â€¦	  |11,00   |
|Albania	    |4,72	    |4,72	    |5,37	    |4,79	    |â€¦    |5,66    |
|Algeria	    |18,93    |22,31    |34,37    |46,47    |â€¦    |180,57  |
|...          |...      |...      |...      |...      |...  |...     |
|GLOBAL TOTAL |15 760,00|15 690,85|16 484,39|17 464,80|	â€¦	  |38 016,5|

<span class='post-paragraph text-sm mb-8'>Å¹rÃ³dÅ‚o: Crippa, M., Guizzardi, D., Muntean, M., Schaaf, E., Solazzo, E., Monforti-Ferrario, F., Olivier, J.G.J., Vignati, E., Fossil CO2 emissions of all world countries - 2020 Report, EUR 30358 EN, Publications Office of the European Union, Luxembourg, 2020, ISBN 978-92-76-21515-8, doi:10.2760/143674, JRC121460.</span>  

  

Wczytujemy dane z pliku za pomocÄ… biblioteki Pandas i metody read_excel podajÄ…c odpowiednio jako parametry:

`pd.read_excel(nazwa_pliku_excel, nazwa_arkusza, index_col=nazwa_kolumny_z_indeksem)`

```python lineNumbers
emission = pd.read_excel('EDGARv5.0_FT2019_fossil_CO2_booklet2020.xls', 'fossil_CO2_totals_by_country', index_col = 'country_name')
index = pd.Index(emission.columns, name='year')
emission = emission.T.reindex(index)['GLOBAL TOTAL'].to_frame()
emission.loc[2010:2023]
```
DziÄ™ki tej operacji moÅ¼emy utworzyÄ‡ ramkÄ™ danych (**DataFrame**) i zapisaÄ‡ jÄ… do zmiennej np. *emmision*. PoniewaÅ¼ chcemy analizowaÄ‡ zmiennoÅ›Ä‡ globalnej wartoÅ›ci emisji CO<sub>2</sub> w czasie, musimy transponowaÄ‡ nasz DataFrame uÅ¼ywajÄ…c metody <span className='inline-code'>transpose</span> (w skrÃ³cie T), czyli w skrÃ³cie zamieniÄ‡ miejscami wiersze z kolumnami. W efekcie uzyskamy pojedynczÄ… seriÄ™ danych dla Å›wiatowej emisji indeksowanÄ… latami. UÅ¼ycie metody <span className='inline-code'>.to_frame()</span> zamienia seriÄ™ danych na DataFrame (ramkÄ™ danych). Zanim tego dokonamy powinniÅ›my utworzyÄ‡ odpowiedni indeks bazujÄ…c na ÅºrÃ³dÅ‚owej ramce uÅ¼ywajÄ…c metody <span class='inline-code'>Index</span> biblioteki Pandas:
`pd.Index(data=tablica_z_latami, name=nazwa_nowego_indeksu)`

ZrÃ³bmy szybkÄ… wizualizacjÄ™ danych:
```python lineNumbers
plt.plot(emission.index, emission['GLOBAL TOTAL'], label="$emisja \:CO_2$", lw=3)
plt.title('Emisja dwutlenku wÄ™gla na Å›wiecie')
plt.xlabel('Lata')
plt.ylabel('Emisja CO2 (Mt/rok)')
plt.legend(loc='right')
plt.show();
```
UÅ¼ywajÄ…c biblioteki **matplotlib**, rysujemy wykres liniowy. Przekazujemy do metody <span class='inline-code'>plot()</span> wczeÅ›niej przygotowane dane. Informacje o latach zawarte sÄ… w indeksie ramki danych *emmision*, natomiast wartoÅ›ci emisji CO<sub>2</sub> w kolumnie *GLOBAL TOTAL*.

Uprzedzam wraÅ¼liwsze osoby, Å¼e rezultaty mogÄ… szokowaÄ‡ ;):

![Wykres zmian poziomu globalnej emisji](./emmision_plot.png)  

Krzywa reprezentujÄ…ca zmieniajÄ…cy siÄ™ globalny poziom emisji dwutlenku wÄ™gla do atmosfery. WidaÄ‡ wyraÅºnie pokazuje, jak bardzo bezlitosna dla Å›rodowiska jest dziaÅ‚alnoÅ›Ä‡ czÅ‚owieka. Ostatnie cztery dekady to niemal dwukrotny wzrost emisji szkodliwych gazÃ³w do atmosfery. JeÅ›li to kogoÅ› nie przekonuje, to sam nie wiem co jest w stanie to zrobiÄ‡â€¦  

PamiÄ™taj, Å¼e naszym celem jest zbadanie wpÅ‚ywu emisji gazÃ³w do atmosfery na poziom globalnego ocieplenia. Jedyne czego nam na tym etapie brakuje toâ€¦ danych dotyczÄ…cych zmian temperatury! 

Na szczÄ™Å›cie jest wiele ÅºrÃ³deÅ‚, z ktÃ³rych moÅ¼emy je pobraÄ‡. WybraÅ‚em dla Ciebie informacje dostÄ™pne na stronie NASA, ktÃ³ra od wielu lat prowadzi analizÄ™ zmian temperatury powierzchni naszej planety w oparciu o dostÄ™pne zbiory danych. Plik moÅ¼esz pobraÄ‡ <a href='https://data.giss.nasa.gov/gistemp/tabledata_v4/GLB.Ts+dSST.csv' className='visible'> tutaj</a>. Zebrane informacje zawierajÄ… szeregi czasowe zmian Å›rednich temperatur powierzchni Ziemi:

|Year	|Jan	|Feb	|Mar	|â€¦	  |Oct	|Nov	|Dec	|J-D	|D-N	|DJF	|MAM	|JJA	|SON  |
|:---	|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|---: |
|1880 |-0,17|-0,23|-0,08|â€¦    |-0,22|-0,20|-0,16|-0,16|***  |***  |-0,10|-0,15|-0,18|
|1881 |-0,18|-0,13|0,04 |â€¦    |-0,20|-0,17|-0,05|-0,07|-0,08|-0,16|0,06 |-0,06|-0,17|
|1882 |0,18 |0,15 |0,05 |â€¦    |-0,23|-0,15|-0,35|-0,10|-0,07|0,09 |-0,08|-0,14|-0,17|
|â€¦    |â€¦    |â€¦    |â€¦    |â€¦    |â€¦    |â€¦    |â€¦    |â€¦    |â€¦    |â€¦    |â€¦    |â€¦    |â€¦    |
|| ||1,03| |1,15 |1,17| |â€¦    |0,90 |0,88 |0,94 |0,93 |0,92 |1,01 |1,01 |0,80 |0,85 |
||2018 |0,82 |0,85 |0,90 |â€¦    |1,02 |0,83 |0,92 |0,85 |0,86 |0,87 |0,87 |0,79 |0,89 |
||2019 |0,94 |0,96 |1,18 |â€¦    |1,02 |1,00 |1,10 |0,98 |0,97 |0,94 |1,02 |0,94 |0,98 |
||â€¦    |â€¦    |â€¦    |â€¦    |â€¦    |â€¦    |â€¦    |â€¦    |â€¦    |â€¦    |â€¦    |â€¦    |â€¦    |â€¦    |||

  
<span class='post-paragraph text-sm mb-8'>Å¹rÃ³dÅ‚o: GISTEMP Team, 2021: GISS Surface Temperature Analysis (GISTEMP), version 4. NASA Goddard Institute for Space Studies. Dataset accessed 2021-03-30 at data.giss.nasa.gov/gistemp/.
Lenssen, N., G. Schmidt, J. Hansen, M. Menne, A. Persin, R. Ruedy, and D. Zyss, 2019: Improvements in the GISTEMP uncertainty model. J. Geophys. Res. Atmos., 124, no. 12, 6307-6326, doi:10.1029/2018JD029522.</span>

ChcielibyÅ›my zbadaÄ‡ Å›rednioroczny poziom zmian temperatury. Do eksploracji potrzebne bÄ™dÄ… nam dane zawarte w kolumnie nazwanej *J-D*, ktÃ³re przechowujÄ… obliczonÄ… na podstawie 12 miesiÄ™cy (styczeÅ„-grudzieÅ„) Å›redniÄ… wartoÅ›Ä‡ zmian tej wielkoÅ›ci fizycznej. W naszej dotychczasowej analizie zajmowaliÅ›my siÄ™ zjawiskami opisywanymi w latach 1970-2019, dlatego przy imporcie danych do ramki, uwzglÄ™dnimy taki wÅ‚aÅ›nie zakres:

```python lineNumbers
gistemp = pd.read_csv('https://data.giss.nasa.gov/gistemp/tabledata_v4/GLB.Ts+dSST.csv', delimiter = ',', skiprows = 1, sep = '.')
gistemp = gistemp[['Year', 'J-D']].set_index(['Year']).loc[1970:2019]
gistemp['J-D'] = gistemp['J-D'].astype(float)
gistemp.head(6)
# Po uruchomieniu kodu widocznych bÄ™dzie 6 pierwszych wierszy ramki:
```

|Year	|J-D|
|---|---:|
|1970	|0.03|
|1971|-0.08|
|1972	|0.01|
|1973	|0.16|
|1974	|-0.07|
|1975	|-0.01|

PoÅ‚Ä…czmy nowo wczytane dane z posiadanymi wczeÅ›niej informacjami o emisji CO<sub>2</sub>...
```python lineNumbers
global_warming = pd.concat([gistemp, emission], axis=1)
global_warming.sample(6)
# Po uruchomieniu kodu widocznych bÄ™dzie 6 losowo wybranych wierszy ramki:
```
|	|J-D	|GLOBAL TOTAL|
|---|---:|---:|
|2017	|0.93	|36794.620795|
|1985	|0.12	|20279.954115|
|1998	|0.61	|24638.044086|
|2009	|0.66	|32090.505920|
|2008	|0.55	|32475.438985|
|1970	|0.03	|15760.000532|

... i zrÃ³bmy szybkÄ… wizualilzacjÄ™:
```python lineNumbers
plt.scatter(global_warming['GLOBAL TOTAL'], global_warming['J-D'], label='zmiana temperatury [$^\circ$C]')
plt.title('Zmiany temperatury powierzchni Ziemi w zaleÅ¼noÅ›ci od emisji CO2')
plt.xlabel('Emisja CO2 [Mt/rok]')
plt.ylabel('Zmiana temperatury powierzchni Ziemi [$^\circ$C]')
plt.legend(loc='upper center')
plt.show();
```
<p></p>

![Wykres zmian temperatury powierzchni Ziemi](./global_warming_scatter.png)

Na wykresie widzimy wyraÅºnie zarysowujÄ…cy siÄ™ trend rosnÄ…cy. 

#### Prosty model regresji liniowej.

AnalizÄ™ opieramy tylko na jednej cesze, ktÃ³rÄ… jest emisja dwutlenku wÄ™gla. 
```python lineNumbers
X = global_warming['GLOBAL TOTAL'].values.reshape(-1, 1)
y = global_warming['J-D'].values.reshape(-1, 1)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=33)
X_train.shape, X_test.shape, y_train.shape, y_test.shape

# PoniÅ¼ej efekt dziaÅ‚ania komendy w linii 5
# >>> ((45, 1), (5, 1), (45, 1), (5, 1))
```
CechÄ™ przekazujemy do zmiennej *X*. Target (poziom zmian temperatury) umieszczamy w zmiennej *y*. Wykorzystamy funkcjÄ™ pomocniczÄ… <span className='inline-code'>train_test_split()</span> do losowego podziaÅ‚u zbioru wartoÅ›ci na czÄ™Å›ci treningowÄ… i testowÄ…. `train_test_split(zbiÃ³r_cech, target, test_size = rozmiar_zbioru_testowego)` Powinno to poprawiÄ‡ skutecznoÅ›Ä‡ trenowania modelu.

MoÅ¼esz zauwaÅ¼yÄ‡, Å¼e wynik dziaÅ‚ania funkcji <span className='inline-code'>train_test_split()</span> to cztery zbiory danych: dwa treningowe (*X_train, y_train*) i dwa testowe (*X_test, y_test*) do walidacji modelu. Zbiory treningowe majÄ… po 45 elementÃ³w, testowe zaÅ› 5. Wynika to z faktu, Å¼e parametr *test_size* przekazany w funkcji miaÅ‚ wartoÅ›Ä‡ 0.1. Oznacza to, Å¼e 10% elementÃ³w caÅ‚ego zbioru, bÄ™dzie przeznaczanych na czÄ™Å›Ä‡ testowÄ… (czyli dokÅ‚adnie 5 z 50 w tym przypadku).  

![Zasada dziaÅ‚ania metody train_test_split()](./train_test_split.jpg)  

Zasada dziaÅ‚ania metody <span className='inline-code'>train_test_split()</span> jest bardzo prosta. Wybiera ona w sposÃ³b losowy elementy naszego zbioru danych, dzielÄ…c go na czÄ™Å›Ä‡ treningowÄ… i testowÄ…. Dla kaÅ¼dego zestawu cech (*X*) w zbiorze treningowym przypisana jest wÅ‚aÅ›ciwa wartoÅ›Ä‡ targetu (*y*). Analogicznie odbywa siÄ™ to dla zbioru testowego. DziÄ™ki takiemu podejÅ›ciu, moÅ¼emy w prosty sposÃ³b poddaÄ‡ model procesowi walidacji (oceny jakoÅ›ci), wykorzystujÄ…c do tego dane treningowe. Warto zaznaczyÄ‡, Å¼e jest to jedna z bardziej podstawowych metod optymalizacji.  

NadszedÅ‚ czas wytrenowaÄ‡ model. UÅ¼ywamy wspominanego juÅ¼ modelu <span className='inline-code'>LinearRegression()</span>

```python lineNumbers
model = LinearRegression()
model.fit(X_train, y_train)
```

Metoda <span className='inline-code'>.fit()</span> odpowiada za wÅ‚aÅ›ciwe trenowanie modelu (czyli obliczanie wspÃ³Å‚czynnikÃ³w rÃ³wnania regresji w tym przypadku), na podstawie zbioru treningowego.  

Aby oceniÄ‡ jakoÅ›Ä‡ wytrenowania modelu, musimy sprawdziÄ‡ jakie bÅ‚Ä™dy popeÅ‚nia. WÅ‚aÅ›nie do tego potrzebny jest zbiÃ³r testowy, ktÃ³ry wczeÅ›niej uzyskaliÅ›my (*X_test*).

```python lineNumbers
y_pred = model.predict(X_test)
```  

Przekazujemy testowy zbiÃ³r cech (*X_test*) do metody <span className='inline-code'>.predict()</span> modelu i zapisujemy wyniki predykcji w zmiennej *y_pred*.  

Teraz mamy juÅ¼ wszystko, Å¼eby policzyÄ‡ bÅ‚Ä…d Å›redniokwadratowy. OczywiÅ›cie jest do tego odpowiednia funkcja w scikit-learn:
`mean_squared_error(predykcje_modelu, wartoÅ›ci_targetu_w_zbiorze_testowym)`

```python lineNumbers
mse = mean_squared_error(y_pred, y_test)
print(f'RMSE:{np.sqrt(mse): .3f}, R2:{model.score(X_test, y_test): .3f}')

# Wynik uruchomienia powyÅ¼szego kodu:
# >>> RMSE: 0.077, R2: 0.932
```  
PoniewaÅ¼ obliczony bÅ‚Ä…d jest wyraÅ¼ony jako Å›redni kwadrat rÃ³Å¼nicy pomiÄ™dzy predykcjÄ… a wartoÅ›ciÄ… rzeczywistÄ…, wyciÄ…gniemy z niego pierwiastek (<span className='inline-code'>np.sqrt(mse)</span>). Taki zabieg pozwoli nam sprowadziÄ‡ wartoÅ›Ä‡ bÅ‚Ä™du do poziomu â€œnominalnegoâ€ (czyli takiego w jakim wyraÅ¼one sÄ… wartoÅ›ci targetu). De facto tak obliczony bÅ‚Ä…d nosi nazwÄ™ **Å›redniej kwadratowej** (*RMSE - Root Mean Squared Error*). Tak, wiem co myÅ›lisz - masÅ‚o maÅ›lane ;p

Dodatkowo posÅ‚uÅ¼ymy siÄ™ dostÄ™pnÄ… w modelu *LinearRegression()* metodÄ… <span className='inline-code'>.score()</span> [2], ktÃ³ra obliczy nam jeszcze jednÄ… metrykÄ™ dopasowania modelu a konkretnie **wspÃ³Å‚czynnik determinacji** (*coefficient of determination*), lub inaczej **R-kwadrat** (*R<sup>2</sup>*). W przypadku idealnego dopasowania modelu do danych, jego wartoÅ›Ä‡ jest bardzo bliska lub rÃ³wna 1 (jednoÅ›ci).  
WartoÅ›Ä‡ bÅ‚Ä™du RMSE nie jest zbyt maÅ‚a, ale na potrzeby tego artykuÅ‚u nie bÄ™dziemy starali siÄ™ go bardziej minimalizowaÄ‡. Wprawne oko zauwaÅ¼y jednÄ… z przyczyn tego problemu. Szybkie spojrzenie na przygotowany wczeÅ›niej wykres ( ) i moÅ¼emy dostrzec, Å¼e przebieg zmiennoÅ›ci wystÄ™powania anomalii temperaturowych w zaleÅ¼noÅ›ci od emisji CO2 nie jest doskonale liniowy. A my uÅ¼ywamy modeluâ€¦? WÅ‚aÅ›nie ğŸ˜‰ Ponadto, wartoÅ›Ä‡ metryki R2 na poziomie 0.93 otwiera nam furtkÄ™ do kolejnego etapu eksperymentu. 

#### Przewidujemy przyszÅ‚oÅ›Ä‡
Do tej pory udaÅ‚o nam siÄ™ wykorzystaÄ‡ model do tego by dowiedzieÄ‡ siÄ™ w jakim stopniu zaleÅ¼ne sÄ… od siebie dwa zjawiska. Tutaj maÅ‚a dygresja. ZwrÃ³Ä‡ uwagÄ™ na to, Å¼e za pomocÄ… tego modelu moÅ¼esz okreÅ›liÄ‡ zaleÅ¼noÅ›Ä‡ iloÅ›ciowÄ… pomiÄ™dzy cechÄ… a targetem. Nie okreÅ›la on jednak jaki jest charakter tej zaleÅ¼noÅ›ci. Inaczej mÃ³wiÄ…c nie odpowiada na pytanie o wzajemne oddziaÅ‚ywanie zjawisk, czyli co jest ÅºrÃ³dÅ‚em a co przyczynÄ… zmiennoÅ›ci. SprÃ³bujmy teraz wykorzystaÄ‡ naszÄ… nowo zdobytÄ… wiedzÄ™ do oszacowania poziomu globalnego ocieplenia w kilku najbliÅ¼szych latach.  

Na wstÄ™pie zrobimy pewne zaÅ‚oÅ¼enie. Przyjmijmy dla uproszczenia, Å¼e wartoÅ›Ä‡ emisji CO2 do atmosfery bÄ™dzie rosÅ‚a co roku o staÅ‚y procent, obliczony na podstawie ostatnich 5 lat. PosÅ‚uÅ¼ymy siÄ™ znanym z analizy finansowej wskaÅºnikiem, znanym jako skumulowany roczny wskaÅºnik wzrostu (CAGR - compound annual growth rate). Obliczamy go w nastÄ™pujÄ…cy sposÃ³b:
$$
CAGR = \left(\frac{EV}{BV}\right)^{\frac{1}{n}} - 1
$$

$EV$ to wartoÅ›Ä‡ cechy w ostatnim roku analizowanego okresu, $BV$ to wartoÅ›Ä‡ w pierwszym roku, $n$ to liczba lat obejmujÄ…cych badany okres. Zaimplementujmy teraz wskaÅºnik CAGR w Python'ie:

```python lineNumbers
def cagr(ending_year, beggining_year, df):
    '''
    ending_year (int) - rok koÅ„cowy
    beggining_year (int) - rok poczÄ…tkowy
    df (DataFrame) - ramka zawierajÄ…ca dane indeksowane latami
    '''
    assert beggining_year in df.index, f'niepoprawny rok poczÄ…tkowy: {beggining_year}'
    assert ending_year in df.index, f'niepoprawny rok koÅ„cowy: {ending_year}'
    assert ending_year != beggining_year, f'data poczÄ…tkowa i koÅ„cowa sÄ… takie same!'
    
    beggining_value = df.loc[beggining_year]
    ending_value = df.loc[ending_year]
    return float(pow( ending_value/beggining_value, 1 / (ending_year - beggining_year) ) - 1 
```
<p></p> 

Policzmy teraz prognozowane wartoÅ›ci emisji CO<sub>2</sub> dla lat 2020-2025. Jako podstawy do kalkulacji uÅ¼yjemy wartoÅ›ci tego czynnika w roku 2019 [1]. Åšrednioroczny wskaÅºnik wzrostu obliczymy na podstawie danych z ostatnich 6 lat (2014 - 2019), wykorzystujÄ…c do tego zdefiniowanÄ… wczeÅ›niej funkcjÄ™ <span className='inline-code'>cagr()</span>[2]:  

```python lineNumbers
base = emission.loc[2019].values[0]
growth = cagr(2014, 2019, emission)
print('emisja CO2 w roku bazowym: %1.2f, Å›rednioroczny wzrost: %1.4f%%' % (base, growth * 100))

# >>> emisja CO2 w roku bazowym: 38016.57, Å›rednioroczny wzrost: 0.9593%
```  

Prosta pÄ™tla [3] pozwoli wykorzystaÄ‡ obliczone przed chwilÄ… wartoÅ›ci do oszacowania przyszÅ‚ego poziomu emisji CO<sub>2</sub>. CaÅ‚oÅ›Ä‡ zapisujemy w nowo utworzonej ramce [1]:  

```python lineNumbers
future_emission = pd.DataFrame()

for year in range(2020, 2026):
    base = base + base * growth
    future_emission = future_emission.append({'year': year, 'GLOBAL TOTAL': base}, ignore_index = True)
    
future_emission['year'] = future_emission['year'].astype(int)
future_emission.set_index('year', inplace=True)
future_emission

# po uruchomieniu powyÅ¼szego kodu zobaczysz zawartoÅ›Ä‡ ramki 'future_emission':
```  

|year	|GLOBAL TOTAL	|
|---  |---:         |
|2020	|38381.253944	|
|2021	|38749.433612	|
|2022	|39121.145116	|
|2023	|39496.422335	|
|2024	|39875.299473	|

ZostaÅ‚o nam juÅ¼ tylko jednoâ€¦ Tak! Wykorzystamy wytrenowany model regresji liniowej do predykcji poziomu globalnego ocieplenia ğŸ™‚ PoniewaÅ¼ znajdujesz siÄ™ juÅ¼ w tym miejscu artykuÅ‚u, nic co znajduje siÄ™ poniÅ¼ej nie jest dla Ciebie magiÄ…. A wiÄ™câ€¦:
```python lineNumbers
X_future = future_emission['GLOBAL TOTAL'].values.reshape(-1, 1)
future_emission['J-D'] = model.predict(X_future)
future_emission

# po uruchomieniu powyÅ¼szego kodu zobaczysz zawartoÅ›Ä‡ ramki 'future_emission' wraz z prognozÄ… w kolumnnie 'J-D':
```
|year	|GLOBAL TOTAL	|J-D     |
|---  |---:         |---:    |
|2020	|38381.253944	|0.926396|
|2021	|38749.433612	|0.940895|
|2022	|39121.145116	|0.955534|
|2023	|39496.422335	|0.970312|
|2024	|39875.299473	|0.985232|
|2025	|40257.811065	|1.000296|

<p></p>

Z pewnoÅ›ciÄ… wizualizacja pomoÅ¼e nam spojrzeÄ‡ na wyniki z lepszej perspektywy:  

```python lineNumbers
emission_range = (np.linspace(global_warming['GLOBAL TOTAL'].min(), global_warming['GLOBAL TOTAL'].max()))

ax1 = plt.subplot(211)
ax1.plot(emission_range, (beta_1 * emission_range + beta_0), c='r', ls=':', label=f'Prosta regresji modelu: Y={beta_1}X + {beta_0}')
ax1.scatter(global_warming['GLOBAL TOTAL'], global_warming['J-D'], label=f'Zarejestrowane zmiany temperatury')
ax1.scatter(future_emission['GLOBAL TOTAL'], future_emission['J-D'], c='w', edgecolor='r', label="Predykcja zmian temperatury")
ax1.set_ylabel('Zmiana temperatury powierzchni Ziemi [$^\circ$C]')
ax1.set_xlabel('Emisja CO2 [Mt/rok]')
ax1.title.set_text('Zmiany temperatury powierzchni Ziemi w zaleÅ¼noÅ›ci od emisji CO2')
ax1.legend()

ax2 = plt.subplot(212)
ax2.plot(global_warming.index, global_warming['J-D'], label=f'Zarejestrowane zmiany temperatury')
ax2.scatter(future_emission.index, future_emission['J-D'], c='w', edgecolor='r', label="Predykcja zmian temperatury")
ax2.set_ylabel('Zmiana temperatury powierzchni Ziemi [$^\circ$C]')
ax2.set_xlabel('Rok')
ax2.set_xticks(range(1970, 2026, 5))
ax2.title.set_text('Zmiany temperatury powierzchni Ziemi w kolejnych latach')
ax2.legend()
plt.tight_layout()
plt.show();
```

<p></p>

![Wykres zmian temperatury powierzchni Ziemi w zaleÅ¼noÅ›ci od emisji CO2](./final_prediction.png)

Widzisz, Å¼e model pozwala nam przewidzieÄ‡ wartoÅ›ci zmian temperatury w przyszÅ‚oÅ›ci na podstawie naszych estymacji poziomu emisji gazÃ³w cieplarnianych do atmosfery. PoniewaÅ¼ zastosowaliÅ›my regresjÄ™ liniowÄ…, odpowiedÅº jakÄ… uzyskaliÅ›my w naszym eksperymencie w sposÃ³b oczywisty ukÅ‚ada siÄ™ wzdÅ‚uÅ¼ linii prostej. Przebieg w czasie punktÃ³w znajdujÄ…cych siÄ™ na prostej, czyli rosnÄ…cy trend, podsuwa wniosek, Å¼e brak regulacji dotyczÄ…cych emisji szkodliwych gazÃ³w, moÅ¼e w bezceremonialny sposÃ³b doprowadziÄ‡ do katastrofy ekologicznej ğŸ™

#### Tylko spokÃ³j nas uratujeâ€¦ (a raczej zdrowy rozsÄ…dek)
Na uspokojenie na koniec maÅ‚e podsumowanie. Zastosowany przez nas model regresji liniowej, jest jednym z najprostszych modeli, a co za tym idzie ma wiele wad i ograniczeÅ„. Do podstawowych naleÅ¼y wÅ‚aÅ›nie jego prostota, ktÃ³ra bardzo czÄ™sto utrudnia dopasowanie do danych. Wynika to z faktu, Å¼e zjawiska zachodzÄ…ce w naszym Å›wiecie zazwyczaj nie majÄ… liniowego charakteru. Nasza prognoza oparta jest tylko na jednym parametrze, pomijajÄ…c tym samy wpÅ‚yw innych czynnikÃ³w na proces ocieplania siÄ™ klimatu. Powoduje to pewnego rodzaju kumulacjÄ™ bÅ‚Ä™du predykcji. Dlatego wyniki, ktÃ³re otrzymaliÅ›my, nie odzwierciedlajÄ… w peÅ‚ni charakteru procesu jakim jest globalne ocieplenie.